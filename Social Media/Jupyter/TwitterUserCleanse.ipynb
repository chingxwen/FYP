{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import csv\n",
    "import re\n",
    "import ast\n",
    "from googletrans import Translator\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which data file do you want to cleanse ?BBCTech\n"
     ]
    }
   ],
   "source": [
    "datefile = input('Which data file do you want to cleanse ?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/User/Desktop/FYP/FYP/Social Media/CSV/Users/' + datefile + '.csv', names = ['User','ID','Date','Tweets'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra rows by date \n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "startdate = '01-07-2018'\n",
    "enddate = '31-10-2019'\n",
    "\n",
    "filterrows = (df['Date'] > startdate) & (df['Date'] <= enddate)\n",
    "\n",
    "df = df.loc[filterrows]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Drop columns \n",
    "df.drop(columns=['ID'], inplace = True)\n",
    "print(type(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# remove 'b' flags\n",
    "df['Tweets'] = df['Tweets'].apply(ast.literal_eval).str.decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove https links\n",
    "df['Tweets'] = df['Tweets'].str.replace(r'http\\S+|www.\\S+', '', case=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         User                Date  \\\n",
      "94    BBCTech 2019-10-30 18:02:41   \n",
      "95    BBCTech 2019-10-30 14:10:17   \n",
      "96    BBCTech 2019-10-30 12:17:00   \n",
      "97    BBCTech 2019-10-30 10:05:38   \n",
      "98    BBCTech 2019-10-29 19:21:01   \n",
      "...       ...                 ...   \n",
      "3225  BBCTech 2018-02-06 08:26:12   \n",
      "3226  BBCTech 2018-02-06 08:15:11   \n",
      "3227  BBCTech 2018-02-06 00:08:03   \n",
      "3228  BBCTech 2018-02-05 23:46:56   \n",
      "3229  BBCTech 2018-02-05 16:23:25   \n",
      "\n",
      "                                                 Tweets  \n",
      "94    DeepMind AI achieves Grandmaster status at Sta...  \n",
      "95       Microsoft's GitHub blocks Catalan protest app   \n",
      "96    Amazon's push for Prime sign-up 'misleading', ...  \n",
      "97    Facebook agrees to pay Cambridge Analytica fin...  \n",
      "98          Currys PC World customers scammed via eBay   \n",
      "...                                                 ...  \n",
      "3225        YouTube Kids still shows disturbing videos   \n",
      "3226        YouTube Kids still shows disturbing videos   \n",
      "3227                                  Computer says no   \n",
      "3228  Electric dreams: The race to develop battery-p...  \n",
      "3229        Technology 'makes workers less productive'   \n",
      "\n",
      "[3136 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Removal of Null Values\n",
    "df['Tweets'].replace('',np.nan,inplace=True)\n",
    "df.dropna(axis = 0, how = 'any', inplace = True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove username in Tweets\n",
    "df['Tweets'] = df['Tweets'].str.replace(r'@[^\\s]+','', case=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Special Characters \n",
    "df['Tweets'] = df['Tweets'].str.replace(r'[^A-Za-z0-9 ]+', '', case = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace empty cells with Nan then Remove Empty Rows\n",
    "df['Tweets'].replace('',np.nan,inplace=True)\n",
    "df.dropna(axis = 0, how = 'any', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        User                Date  \\\n",
      "94   BBCTech 2019-10-30 18:02:41   \n",
      "95   BBCTech 2019-10-30 14:10:17   \n",
      "96   BBCTech 2019-10-30 12:17:00   \n",
      "97   BBCTech 2019-10-30 10:05:38   \n",
      "98   BBCTech 2019-10-29 19:21:01   \n",
      "99   BBCTech 2019-10-29 16:09:12   \n",
      "100  BBCTech 2019-10-29 13:39:07   \n",
      "101  BBCTech 2019-10-28 18:29:08   \n",
      "102  BBCTech 2019-10-28 17:27:56   \n",
      "103  BBCTech 2019-10-28 16:16:27   \n",
      "\n",
      "                                                Tweets  \n",
      "94   DeepMind AI achieves Grandmaster status at Sta...  \n",
      "95       Microsofts GitHub blocks Catalan protest app   \n",
      "96   Amazons push for Prime signup misleading says ...  \n",
      "97   Facebook agrees to pay Cambridge Analytica fin...  \n",
      "98         Currys PC World customers scammed via eBay   \n",
      "99   RT  LISTEN How dangerous are deepfakes In an e...  \n",
      "100  Call of Duty faces Russian backlash over Highw...  \n",
      "101                       Make or break moment for 5G   \n",
      "102                Georgia hit by massive cyberattack   \n",
      "103    Fitbit shares halted on Google takeover report   \n"
     ]
    }
   ],
   "source": [
    "# Removal of Null Values\n",
    "df['Tweets'].replace('',np.nan,inplace=True)\n",
    "df['Tweets'].replace(' ',np.nan,inplace=True)\n",
    "df['Tweets'].replace('  ',np.nan,inplace=True)\n",
    "df['Tweets'].replace('   ',np.nan,inplace=True)\n",
    "df['Tweets'].replace('    ',np.nan,inplace=True)\n",
    "df.dropna(axis = 0, how = 'any', inplace = True)\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert datetime to date time\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removal of Trailing White Spaces\n",
    "dfframe = df['Tweets'].to_frame()\n",
    "dflist = df['Tweets'].tolist()\n",
    "\n",
    "dftweet2 = df['Tweets'].str.strip()\n",
    "df2 = dftweet2.to_frame()\n",
    "\n",
    "final = pd.concat([df['User'], df['Date'], df['Tweets']], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list DataFrame to csv\n",
    "pd.DataFrame.from_dict(data = final , orient = 'columns').to_csv('C:/Users/User/Desktop/FYP/FYP/Social Media/CSV/Cleanse/' + datefile + 'Cleanse.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
