{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Of libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading of csv merged \n",
    "df = pd.read_csv(r\"C:\\Users\\Jurgen\\Desktop\\FYP\\Shared\\CSV Files\\News_Twitter_Stock_Reddit_NaN_Final.csv\")\n",
    "# Dropping of columns that are not required\n",
    "df = df.drop([\"Date\", \"Stockname\", \"Close_USD\", \"High_USD\", \"Low_USD\"], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(r\"C:\\Users\\charmaine\\Desktop\\YEAR3\\FYP\\FYP\\Shared\\CSV Files\\News_Twitter_Stock_Reddit_NaN_Final.csv\")\n",
    "# df = df.drop([\"Date\", \"Stockname\", \"Close_USD\", \"High_USD\", \"Low_USD\"], axis=1)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non NaN Stock Data + Sentiments Filled With 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling of NaN values from sentiment columns with 0 \n",
    "df[[\"News_Senti\",\n",
    "    \"Twitter_Senti\", \n",
    "    \"Reddit_Comment\", \n",
    "    \"Reddit_SelfText\"]] = df[[\"News_Senti\",\n",
    "                              \"Twitter_Senti\", \n",
    "                              \"Reddit_Comment\", \n",
    "                              \"Reddit_SelfText\"]].fillna(0)\n",
    "\n",
    "#Dropping of rows that are NaN in the stocks column\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# #Splitting of data into training and testing sets\n",
    "x = df.loc[:, df.columns != 'Adj_Close_USD']\n",
    "X = x.to_numpy()\n",
    "y = df[\"Adj_Close_USD\"].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=0)\n",
    "\n",
    "print(\"Training Rows: \",X_train.shape[0])\n",
    "print(\"Testing Rows: \",X_test.shape[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regr = LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('R^2: %.8f'\n",
    "      % r2_score(y_test, y_pred))\n",
    "# The intercept\n",
    "print(\"Intercept: \", regr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Show The Difference Between The Actual & Predicted\n",
    "test = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred, 'Difference': (y_pred - y_test)})\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lineplot showing Actual vs Predicted\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot outputs\n",
    "plt.figure(figsize = (18, 10))\n",
    "plt.plot(y_test, color = \"red\")\n",
    "plt.plot(y_pred, color = \"green\")\n",
    "\n",
    "plt.xlabel(\"Day\", fontsize = 18)\n",
    "plt.ylabel(\"Adjusted Close (USD)\", fontsize = 18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatterplot\n",
    "import matplotlib.pyplot as plt\n",
    "#Figure size\n",
    "plt.figure(figsize = (18, 10))\n",
    "\n",
    "#Plotting of scatterplot\n",
    "plt.scatter(y_test, y_pred, s = 200, color = \"blue\", alpha = 0.5) #Increasing size and transparency\n",
    "\n",
    "#Plotting of regression line\n",
    "m, b = np.polyfit(y_test, y_pred, deg=1)\n",
    "plt.plot(y_test, m*y_test+b, color = \"red\", linewidth = 2)\n",
    "\n",
    "#Labelling\n",
    "plt.title(\"Predicted vs Actual\", fontsize = 18, fontweight = \"bold\")\n",
    "plt.xlabel(\"Actual\", fontsize = 16)\n",
    "plt.ylabel(\"Predicted\", fontsize = 16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT USED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(r\"C:\\Users\\Jurgen\\Desktop\\FYP\\Shared\\Tableau Dashboard\\Summarised\\Tableau_Phase2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn import metrics\n",
    "\n",
    "# #Choosing the number of estimators that fits the model the best \n",
    "# r2_value = []\n",
    "# for i in range(100, 1100, 100):\n",
    "#     model = RandomForestRegressor(n_estimators=i, random_state=0)\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     r2_value.append((metrics.r2_score(y_test, y_pred),i))\n",
    "#     print(\"R^2: {:.8f} n_estimators = {}\".format(metrics.r2_score(y_test, y_pred), i))\n",
    "\n",
    "# r2 = pd.DataFrame(r2_value, columns = [\"R2\", \"n_estimators\"]).set_index(\"n_estimators\")\n",
    "# n_est = r2.R2[r2.R2 == r2.R2.max()].index[0]\n",
    "\n",
    "\n",
    "# model = RandomForestRegressor(n_estimators = n_est, random_state=0)\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# print()\n",
    "# print(\"N_Estimators: \", n_est)\n",
    "# print('Coefficients: \\n', model.feature_importances_)\n",
    "# print(\"Adjusted R Square: \", metrics.r2_score(y_test, y_pred))\n",
    "# print(\"Variance Score: \", metrics.explained_variance_score(y_test, y_pred))\n",
    "# print(\"Max Error: \", metrics.max_error(y_test, y_pred))\n",
    "# print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "# print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "# print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fi = pd.DataFrame({'Feature': list(x.columns),\n",
    "#                    'Importance': model.feature_importances_}).\\\n",
    "#                     sort_values('Importance', ascending = False)\n",
    "# fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping All Rows With NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_dropped = df.dropna().reset_index(drop=True)\n",
    "# df_dropped.shape\n",
    "\n",
    "\n",
    "# X = df_dropped.loc[:, df_dropped.columns != 'Adj_Close_USD'].to_numpy()\n",
    "# y = df_dropped[\"Adj_Close_USD\"].to_numpy()\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# print(\"Training Rows: \",X_train.shape[0])\n",
    "# print(\"Testing Rows: \",X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import eli5\n",
    "# from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# feature = df.loc[:,df.columns != 'Adj_Close_USD'].columns.values.tolist()\n",
    "\n",
    "# feature_x = []\n",
    "# for i in range(6):\n",
    "#     feature_x.append(\"x\" + str(i))\n",
    "# feature_x\n",
    "\n",
    "# weight_relation = pd.DataFrame({\"Columns\" : feature, \n",
    "#                                 \"Feature\" : feature_x}).set_index(\"Feature\")\n",
    "# print(weight_relation)\n",
    "\n",
    "\n",
    "# perm = PermutationImportance(text_classifier).fit(X_test, y_test)\n",
    "# eli5.show_weights(perm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import neighbors\n",
    "# from sklearn.metrics import mean_squared_error \n",
    "# from math import sqrt\n",
    "\n",
    "# rmse_val = [] #to store rmse values for different k\n",
    "# for K in range(20):\n",
    "#     K = K+1\n",
    "#     model = neighbors.KNeighborsRegressor(n_neighbors = K)\n",
    "\n",
    "#     model.fit(X_train, y_train)  #fit the model\n",
    "#     pred=model.predict(X_test) #make prediction on test set\n",
    "#     error = sqrt(mean_squared_error(y_test, pred)) #calculate rmse\n",
    "#     rmse_val.append(error) #store rmse values\n",
    "    \n",
    "# rmse_val = pd.DataFrame(rmse_val)\n",
    "# print(rmse_val)\n",
    "# print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import neighbors\n",
    "# from sklearn.metrics import mean_squared_error \n",
    "# from math import sqrt\n",
    "# import numpy as np\n",
    "\n",
    "# rmse_val = [] #to store rmse values for different k\n",
    "# for K in range(7):\n",
    "#     K = K+1\n",
    "#     model = neighbors.KNeighborsRegressor(n_neighbors = K)\n",
    "\n",
    "#     model.fit(X_train, y_train)  #fit the model\n",
    "#     pred=model.predict(X_test) #make prediction on test set\n",
    "#     error = sqrt(mean_squared_error(y_test, pred)) #calculate rmse\n",
    "#     rmse_val.append(error) #store rmse values\n",
    "    \n",
    "# rmse_val = pd.DataFrame(rmse_val)\n",
    "# # print(rmse_val)\n",
    "# print(\"K = \",rmse_val.idxmin()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# from sklearn import neighbors\n",
    "# from math import sqrt\n",
    "\n",
    "# knn = neighbors.KNeighborsRegressor(n_neighbors = 6)\n",
    "# knn.fit(X_train, y_train)\n",
    "# y_pred = knn.predict(X_test)\n",
    "\n",
    "# print(\"Adjusted R Square: \", metrics.r2_score(y_test, y_pred))\n",
    "# print(\"Variance Score: \", metrics.explained_variance_score(y_test, y_pred))\n",
    "# print(\"Max Error: \", metrics.max_error(y_test, y_pred))\n",
    "# print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "# print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "# print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifier\n",
    "\n",
    "# df1 = pd.read_csv(r\"C:\\Users\\Jurgen\\Desktop\\FYP\\News\\SK-Learn\\News_Stock_Data_30.csv\")\n",
    "# X = df1[\"News_Senti\"].to_numpy().reshape(-1, 1)\n",
    "# y = df1[\"Stock_Changes\"].to_numpy()\n",
    "# df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn import metrics\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=100)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = clf.predict(X_test)\n",
    "# # Model Accuracy, how often is the classifier correct?\n",
    "# print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in range(len(y_test)):\n",
    "#     if y_test[i] == y_pred[i]:\n",
    "#         count += 1\n",
    "# print(count, '/', len(y_test))\n",
    "# print(y_test)\n",
    "# print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
